x-rails: &rails
  image: fpc-dev
  pull_policy: never
  tty: true
  stdin_open: true
  build:
    context: .
    target: dev
  environment:
    NEW_RELIC_LOG: stdout
    NODE_ENV: development
    PORT: 80
    POSTGRES_PASSWORD: fpc
    POSTGRES_USER: fpc
    RAILS_MAX_THREADS: 5
    REDIS_CACHE_URL: redis://redis:6379/1
    REDIS_PROVIDER: REDIS_URL
    REDIS_URL: redis://redis:6379/0
    USE_OLLAMA: "true"
  env_file:
    - path: ./.env
      required: true
    - path: ./.env.local
      required: false

  depends_on:
    postgres:
      condition: service_started
    redis:
      condition: service_started
    ollama:
      condition: service_healthy
  volumes:
    - .:/app
    - gem_cache:/usr/local/bundle

services:
  postgres:
    image: pgvector/pgvector:pg16
    volumes:
      - postgres_data:/var/lib/postgresql/data:cached
    environment:
      POSTGRES_USER: fpc
      POSTGRES_PASSWORD: fpc
    ports:
      - 5432:5432
  redis:
    image: redis:7-alpine
    command: redis-server
    volumes:
      - redis_data:/data:cached
    ports:
      - 6379:6379
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - 11434:11434
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "ollama list | grep -q 'llama3.2:3b' && ollama list | grep -q 'nomic-embed-text'"
        ]
      # Wait up to 10 minutes (interval * retries) for Ollama to be ready and models to be pulled
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 60s
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "ollama serve &
      sleep 5 &&
      ollama pull llama3.2:3b &&
      ollama pull nomic-embed-text &&
      wait"
  app:
    <<: *rails
    command: bundle exec puma
    ports:
      - 80:80
  webpack:
    <<: *rails
    command: yarn dev
  sidekiq:
    <<: *rails
    command: bundle exec sidekiq

volumes:
  gem_cache:
  postgres_data:
  redis_data:
  ollama_data:
